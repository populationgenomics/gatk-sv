"use strict";(self.webpackChunkGATK_SV=self.webpackChunkGATK_SV||[]).push([[1420],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>h});var a=n(7294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),u=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=u(e.components);return a.createElement(l.Provider,{value:t},e.children)},d="mdxType",p={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=u(n),m=r,h=d["".concat(l,".").concat(m)]||d[m]||p[m]||i;return n?a.createElement(h,o(o({ref:t},c),{},{components:n})):a.createElement(h,o({ref:t},c))}));function h(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[d]="string"==typeof e?e:r,o[1]=s;for(var u=2;u<i;u++)o[u]=n[u];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},5162:(e,t,n)=>{n.d(t,{Z:()=>o});var a=n(7294),r=n(6010);const i={tabItem:"tabItem_Ymn6"};function o(e){let{children:t,hidden:n,className:o}=e;return a.createElement("div",{role:"tabpanel",className:(0,r.Z)(i.tabItem,o),hidden:n},t)}},4866:(e,t,n)=>{n.d(t,{Z:()=>N});var a=n(7462),r=n(7294),i=n(6010),o=n(2466),s=n(6550),l=n(1980),u=n(7392),c=n(12);function d(e){return function(e){return r.Children.map(e,(e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}(e).map((e=>{let{props:{value:t,label:n,attributes:a,default:r}}=e;return{value:t,label:n,attributes:a,default:r}}))}function p(e){const{values:t,children:n}=e;return(0,r.useMemo)((()=>{const e=t??d(n);return function(e){const t=(0,u.l)(e,((e,t)=>e.value===t.value));if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[t,n])}function m(e){let{value:t,tabValues:n}=e;return n.some((e=>e.value===t))}function h(e){let{queryString:t=!1,groupId:n}=e;const a=(0,s.k6)(),i=function(e){let{queryString:t=!1,groupId:n}=e;if("string"==typeof t)return t;if(!1===t)return null;if(!0===t&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:t,groupId:n});return[(0,l._X)(i),(0,r.useCallback)((e=>{if(!i)return;const t=new URLSearchParams(a.location.search);t.set(i,e),a.replace({...a.location,search:t.toString()})}),[i,a])]}function g(e){const{defaultValue:t,queryString:n=!1,groupId:a}=e,i=p(e),[o,s]=(0,r.useState)((()=>function(e){let{defaultValue:t,tabValues:n}=e;if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(t){if(!m({value:t,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${t}" but none of its children has the corresponding value. Available values are: ${n.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return t}const a=n.find((e=>e.default))??n[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:i}))),[l,u]=h({queryString:n,groupId:a}),[d,g]=function(e){let{groupId:t}=e;const n=function(e){return e?`docusaurus.tab.${e}`:null}(t),[a,i]=(0,c.Nk)(n);return[a,(0,r.useCallback)((e=>{n&&i.set(e)}),[n,i])]}({groupId:a}),b=(()=>{const e=l??d;return m({value:e,tabValues:i})?e:null})();(0,r.useLayoutEffect)((()=>{b&&s(b)}),[b]);return{selectedValue:o,selectValue:(0,r.useCallback)((e=>{if(!m({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);s(e),u(e),g(e)}),[u,g,i]),tabValues:i}}var b=n(2389);const f={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};function k(e){let{className:t,block:n,selectedValue:s,selectValue:l,tabValues:u}=e;const c=[],{blockElementScrollPositionUntilNextRender:d}=(0,o.o5)(),p=e=>{const t=e.currentTarget,n=c.indexOf(t),a=u[n].value;a!==s&&(d(t),l(a))},m=e=>{let t=null;switch(e.key){case"Enter":p(e);break;case"ArrowRight":{const n=c.indexOf(e.currentTarget)+1;t=c[n]??c[0];break}case"ArrowLeft":{const n=c.indexOf(e.currentTarget)-1;t=c[n]??c[c.length-1];break}}t?.focus()};return r.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.Z)("tabs",{"tabs--block":n},t)},u.map((e=>{let{value:t,label:n,attributes:o}=e;return r.createElement("li",(0,a.Z)({role:"tab",tabIndex:s===t?0:-1,"aria-selected":s===t,key:t,ref:e=>c.push(e),onKeyDown:m,onClick:p},o,{className:(0,i.Z)("tabs__item",f.tabItem,o?.className,{"tabs__item--active":s===t})}),n??t)})))}function y(e){let{lazy:t,children:n,selectedValue:a}=e;const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(t){const e=i.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:"margin-top--md"}):null}return r.createElement("div",{className:"margin-top--md"},i.map(((e,t)=>(0,r.cloneElement)(e,{key:t,hidden:e.props.value!==a}))))}function v(e){const t=g(e);return r.createElement("div",{className:(0,i.Z)("tabs-container",f.tabList)},r.createElement(k,(0,a.Z)({},e,t)),r.createElement(y,(0,a.Z)({},e,t)))}function N(e){const t=(0,b.Z)();return r.createElement(v,(0,a.Z)({key:String(t)},e))}},3686:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>u,toc:()=>d});var a=n(7462),r=(n(7294),n(3905)),i=n(4866),o=n(5162);const s={title:"Automated Deployment",description:"Build and Publish Images",sidebar_position:2},l=void 0,u={unversionedId:"advanced/docker/deploy/automated",id:"advanced/docker/deploy/automated",title:"Automated Deployment",description:"Build and Publish Images",source:"@site/docs/advanced/docker/deploy/automated.md",sourceDirName:"advanced/docker/deploy",slug:"/advanced/docker/deploy/automated",permalink:"/gatk-sv/docs/advanced/docker/deploy/automated",draft:!1,editUrl:"https://github.com/broadinstitute/gatk-sv/tree/master/website/docs/advanced/docker/deploy/automated.md",tags:[],version:"current",sidebarPosition:2,frontMatter:{title:"Automated Deployment",description:"Build and Publish Images",sidebar_position:2},sidebar:"tutorialSidebar",previous:{title:"Deploying Docker Images",permalink:"/gatk-sv/docs/advanced/docker/deploy/"},next:{title:"Manual Deployment",permalink:"/gatk-sv/docs/advanced/docker/deploy/manual"}},c={},d=[{value:"Workflow Layout",id:"workflow-layout",level:2},{value:"Determine Build Args",id:"args",level:3},{value:"Testing Docker Image Build",id:"build",level:3},{value:"Publishing Docker Images",id:"publish",level:3}],p={toc:d},m="wrapper";function h(e){let{components:t,...n}=e;return(0,r.kt)(m,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,"In the GATK-SV pipeline, the Docker images undergo automated\nprocesses for building, testing, and publishing as part of\nthe CI/CD workflow. These automated procedures guarantee\nthat all images are consistently and reproducibly built\nwithin a standardized Linux VM environment\n(specifically, GitHub Actions).\nThis ensures uniformity across all GATK-SV Docker images\nand keeps them synchronized with the latest code-base."),(0,r.kt)("p",null,"The automated CI/CD pipeline also includes continuous\ntesting and regression identification during pull requests.\nThis proactive approach allows for the detection and\nresolution of any issues related to image changes or content\nbefore merging the pull request.\nConsequently, it ensures the reliability and consistency\nof the Docker images, simplifies the review process,\nand maintains the high quality of the pipeline."),(0,r.kt)("p",null,"Additionally, the automated CI/CD workflow ensures that\nthe Docker images are correctly mirrored on multiple\ncontainer registries, specifically Azure Container Registry (ACR)\nand Google Cloud Container Registry (GCR).\nThis redundancy guarantees availability and accessibility\nof the images across different platforms."),(0,r.kt)("p",null,"Latest Docker images are listed in the files,\nwith detailed automated deployment descriptions in the following sections."),(0,r.kt)(i.Z,{groupId:"cr",defaultValue:"gcr",values:[{label:"ACR",value:"acr"},{label:"GCR",value:"gcr"}],mdxType:"Tabs"},(0,r.kt)(o.Z,{value:"acr",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"gatk_sv_codebase/inputs/values/dockers_azure.json\n"))),(0,r.kt)(o.Z,{value:"gcr",mdxType:"TabItem"},(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-shell"},"gatk_sv_codebase/inputs/values/dockers.json\n")))),(0,r.kt)("h2",{id:"workflow-layout"},"Workflow Layout"),(0,r.kt)("p",null,"The CI/CD workflow for building, testing, and publishing GATK-SV Docker images\nis defined in ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/broadinstitute/gatk-sv/blob/main/.github/workflows/sv_pipeline_docker.yml"},(0,r.kt)("inlineCode",{parentName:"a"},"sv_pipeline.yml")),".\nThe ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/broadinstitute/gatk-sv/blob/main/scripts/docker/build_docker.py"},(0,r.kt)("inlineCode",{parentName:"a"},"build_docker.py")),"\nscript is utilized for building and publishing the images.\nWhen a pull request is issued against the repository, the images are built,\nand upon merging the pull request, they are published to ACR and GCR."),(0,r.kt)("p",null,"The workflow consists of three\n",(0,r.kt)("a",{parentName:"p",href:"https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#jobs"},(0,r.kt)("em",{parentName:"a"},"jobs")),"\ndiscussed in the following sections."),(0,r.kt)("h3",{id:"args"},"Determine Build Args"),(0,r.kt)("p",null,"This job is responsible for determining the arguments to be used by the\n",(0,r.kt)("inlineCode",{parentName:"p"},"build_docker.py")," script, specifically:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Determining commit SHAs"),":\nConsidering the size and number of GATK-SV Docker images,\nthe workflow focuses on building and publishing only the\nDocker images that are affected by the changes introduced\nin a pull request (PR).\nYou may refer to ",(0,r.kt)("a",{parentName:"p",href:"/docs/advanced/docker/deploy/incremental"},"this page"),"\non details regarding the incremental build strategy.\nThis job determines the commit SHAs of ",(0,r.kt)("inlineCode",{parentName:"p"},"HEAD")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"BASE"),"\ncommits.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Compose image tag"),":\nGATK-SV Docker images are tagged with a consistent template\nto simplify referencing and usage in the pipeline.\nThe tag composition step follows the following template."),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre"},"[DATE]-[RELEASE_TAG]-[HEAD_SHA_8]\n")),(0,r.kt)("p",{parentName:"li"},"where ",(0,r.kt)("inlineCode",{parentName:"p"},"[DATE]")," represents the ",(0,r.kt)("inlineCode",{parentName:"p"},"YYYY-MM-DD")," format extracted\nfrom the timestamp of the last commit on the branch associated\nwith the pull request. ",(0,r.kt)("inlineCode",{parentName:"p"},"RELEASE_TAG")," is extracted from the\nlatest ","[pre-]","release on GitHub.\nAdditionally, ",(0,r.kt)("inlineCode",{parentName:"p"},"HEAD_SHA_8")," denotes the first eight characters\nof the ",(0,r.kt)("inlineCode",{parentName:"p"},"HEAD")," commit SHA. The following is an example tag generated\nin this step."),(0,r.kt)("pre",{parentName:"li"},(0,r.kt)("code",{parentName:"pre"},"2023-05-24-v0.27.3-beta-1796b665\n")))),(0,r.kt)("h3",{id:"build"},"Testing Docker Image Build"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Test Images Build")," job is triggered when a commit is pushed to\nthe pull request branch. It is responsible for\nbuilding the Docker images identified by the\n",(0,r.kt)("a",{parentName:"p",href:"#args"},(0,r.kt)("inlineCode",{parentName:"a"},"Determine Build Args")),"\njob. If the Docker image building process fails,\nthis job will also fail. The Docker images created\nby this job are not published to GCR or ACR and\nare discarded once the job is successfully completed.\nThis job primarily serves for testing purposes during\nthe review process, ensuring that the affected images\ncan be successfully built and that the changes introduced\nin the pull request do not disrupt the Docker build process."),(0,r.kt)("h3",{id:"publish"},"Publishing Docker Images"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Publish")," job is triggered when a pull request\nis merged or a commit is pushed to the ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," branch.\nSimilar to the ",(0,r.kt)("a",{parentName:"p",href:"#build"},(0,r.kt)("inlineCode",{parentName:"a"},"Test Images Build"))," job,\nit builds Docker images; however, in addition,\nthis job also pushes the built images to the GCR and ACR,\nand updates the list of published images. Specifically,\nthis job runs the following steps. "),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Login to ACR"),":\nTo authorize access to the Azure Container Registry (ACR),\nthis job logs in to Docker by assuming an Azure service principal.\nThe credentials required for the login are defined as\n",(0,r.kt)("a",{parentName:"p",href:"https://docs.github.com/en/actions/security-guides/encrypted-secrets"},"encrypted environment secrets"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Login to GCR"),":\nSimilar to ACR, to authorize access to GCR,\nthis job assumes a Google Cloud Platform service account.\nThe secrets related to the service account are defined as\n",(0,r.kt)("a",{parentName:"p",href:"https://docs.github.com/en/actions/security-guides/encrypted-secrets"},"encrypted environment secrets"),".")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Build and publish to ACR and GCR"),":\nSimilar to the ",(0,r.kt)("a",{parentName:"p",href:"#build"},"build job"),", this job builds Docker images\nbased on the list of changed files specified using the\n",(0,r.kt)("inlineCode",{parentName:"p"},"HEAD")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"BASE")," commit SHA. Additionally, it pushes the\nbuilt images to both ACR and GCR. It's important to note\nthat the job doesn't rebuild separate images for each registry.\nInstead, it labels a single image for both ACR and GCR,\nresulting in an identical image with the same tag and Docker\nimage hash being pushed to both registries.\nThis job will fail if the build or push process encounters any issues.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Update the list of published images"),":\nGATK-SV maintains two JSON files that store the latest Docker\nimages built and pushed to ACR and GCR.\nThese files require updates whenever a new image is successfully\nbuilt and published. The ",(0,r.kt)("inlineCode",{parentName:"p"},"build_docker")," script handles the\nupdate of the JSON files by adding the latest built and\npublished Docker images for ACR and GCR."),(0,r.kt)("p",{parentName:"li"},"However, it's important to note that the updated JSON\nfiles reside in the GitHub Actions virtual machines,\nand they are discarded once the GitHub Actions job is\ncompleted successfully. To preserve these changes,\nwe need to commit them to the ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," branch from within the\nGitHub Actions VM as part of the CI/CD process.\nTo achieve this, we utilize a dedicated ",(0,r.kt)("em",{parentName:"p"},"bot")," account.\nThe steps necessary to perform this are explained",(0,r.kt)("br",{parentName:"p"}),"\n","in the following."),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Login to git using the bot's Personal Access Token (PAT)"),":\nThis step is necessary to enable the ",(0,r.kt)("em",{parentName:"p"},"bot")," account to\ncommit the modified JSON files to the ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," branch\nand to authorize the ",(0,r.kt)("em",{parentName:"p"},"bot")," to push the changes from\nthe GitHub Actions VM to the ",(0,r.kt)("inlineCode",{parentName:"p"},"main")," branch using its credentials.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Commit changes and push to the ",(0,r.kt)("inlineCode",{parentName:"strong"},"main")," branch"),":\nThis step configures the Git installation in the\nGitHub Actions VMs using the ",(0,r.kt)("em",{parentName:"p"},"bot"),"'s credentials.\nIt commits the modified JSON files, which contain\nthe latest built and pushed images. The commit message\nreferences the Git commit that triggered the ",(0,r.kt)("a",{parentName:"p",href:"#publish"},"publish")," job,\nproviding improved tracking of changes in the Git history.\nFinally, it pushes the commit to the main branch.\nIt's worth noting that Git is intelligent enough\nto recognize that this push is made from a GitHub\nActions environment, preventing it from triggering\nanother publish job. This avoids the issue of\ninfinite triggers of the publish job."))))))}h.isMDXComponent=!0}}]);